# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
tbl_2 <- test %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dropout(rate = 0.3) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mean_squared_error', optimizer = 'adam')
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
tbl_2 <- test %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dropout(rate = 0.3) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
tbl_2 <- test %>%
add_column(key = "actual")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dropout(rate = 0.3) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
tbl_2 <- test %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
epochs       <- 1000
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dropout(rate = 0.3) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
tbl_2 <- test %>%
add_column(key = "actual")
epochs       <- 500
model <- keras_model_sequential()
model %>%
layer_lstm(units            = 50,
input_shape      = c(tsteps, 1),
batch_size       = batch_size,
return_sequences = TRUE,
stateful         = TRUE) %>%
layer_dropout(rate = 0.4) %>%
layer_lstm(units            = 50,
return_sequences = FALSE,
stateful         = TRUE) %>%
layer_dense(units = 1)
model %>%
compile(loss = 'mae', optimizer = 'adam')
for (i in 1:epochs) {
model %>% fit(x          = x_train_arr,
y          = y_train_arr,
batch_size = batch_size,
epochs     = 1,
verbose    = 1,
shuffle    = FALSE)
model %>% reset_states()
cat("Epoch: ", i)
}
# Make Predictions
pred_out <- model %>%
predict(x_test_arr, batch_size = batch_size) %>%
.[,1]
# Retransform values
pred_tbl <- tibble(
index   = lag_test_tbl$index,
price   = (pred_out * scale_history + center_history)^2
)
# Combine actual data with predictions
tbl_1 <- train %>%
add_column(key = "actual")
tbl_2 <- test %>%
add_column(key = "actual")
tbl_3 <- pred_tbl %>%
add_column(key = "predict")
# Create time_bind_rows() to solve dplyr issue
time_bind_rows <- function(data_1, data_2, index) {
index_expr <- enquo(index)
bind_rows(data_1, data_2) %>%
as_tbl_time(index = !! index_expr)
}
ret <- list(tbl_1, tbl_2, tbl_3) %>%
reduce(time_bind_rows, index = index) %>%
arrange(key, index) %>%
mutate(key = as_factor(key))
calc_rmse <- function(prediction_tbl) {
rmse_calculation <- function(data) {
data %>%
spread(key = key, value = price) %>%
select(-index) %>%
filter(!is.na(predict)) %>%
rename(
truth    = actual,
estimate = predict
) %>%
rmse(truth, estimate)
}
safe_rmse <- possibly(rmse_calculation, otherwise = NA)
safe_rmse(prediction_tbl)
}
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("{id}, RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(id = '', alpha = 1) +
theme(legend.position = "bottom")
plot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {
rmse_val <- calc_rmse(data)
g <- data %>%
ggplot(aes(index, price, color = key)) +
geom_point(alpha = alpha, size = size) +
theme_tq(base_size = base_size) +
scale_color_tq() +
theme(legend.position = "none") +
labs(
title = glue("RMSE: {round(rmse_val, digits = 1)}"),
x = "", y = ""
)
return(g)
}
ret %>%
plot_prediction(alpha = 1) +
theme(legend.position = "bottom")
adf.test(dprice, alternative = "stationary")
library('ggplot2')
library('forecast')
library('tseries')
library('keras')
library('recipes')
library('timetk')
library('tidyquant')
library('tibbletime')
library('yardstick')
library('glue')
library('tidyverse')
ggplot(bean, aes(index, price)) + geom_line() + scale_x_date('Time')  + ylab("Price") +
xlab("")
#ma process 확인
ggplot() +
geom_line(data = bean, aes(x = date, y = price, colour = "Price")) +
geom_line(data = bean, aes(x = date, y = ma,   colour = "Weekly Moving Average"))  +
geom_line(data = bean, aes(x = date, y = ma30, colour = "Monthly Moving Average"))  +
ylab('Price')
decomp <- stl(ma, s.window = "periodic")
deseasonal_price <- seasadj(decomp)
plot(decomp)
summary(model)
summary(pred_out)
